---
title: "Women Who Code LLMs Webinars"
date: 2023-06-06 22:03
last_modified_at: 2023-06-06 23:05
tags:
  - data-science
  - llms
---

### 

# Women Who Code LLMs Webinars

## Intro to LLMs

* Archana Vaidheeswaran (Data Product Manager @ Women Who Code)
* The recording will be uploaded to [WWCode Youtube Channel](https://www.youtube.com/c/WomenWhoCodeGlobal).
* Tokenization
	* Both RNNs and CNNs involved significant data preprocessing. This is where tokenization comes in. Tokenization is the process of splitting a sentence into individual words or characters(tokens). It's like chopping a sentence into pieces so the model can look at each piece.
* In 2017, Vaswani et al. at Google Brain introduced the Transformer model in their paper, "Attention is All You Need'. The Transformer model was a major
breakthrough as it could process all tokens in the
input data in parallel (like CNNs) while also maintaining a sense of order or sequence (like RNN)

## Links

